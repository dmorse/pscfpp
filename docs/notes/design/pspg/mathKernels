TODO (pspg GPU code):

Clean up of simple vector linear algebra kernel functions
----------------------------------------------------------

1) Create a new public branch vector in which to do clean up.
   Submit partial but functional changes to that.

2) Comment out (first) then erase (second) unused kernels.
   Some are found in solvers/Block.tpp and (possibly?) math/Helpers.cu
   (From Ryan: definitely some in math/Helpers.cu!)

3) Analyze what operations in the current pspg code are or should be 
   implemented by calling a standard linear algebra operation like
   one of those described below. That will give a list of operations
   that are needed immediately, and may identify some possible 
   operations that we actually don't need immediately. 

4) Establish more consistent function name conventions for a new
   set of functions in pscf/cuda/LinearAlgebra files.

   Proposal: One way to do this would be to write and test copies 
   with new names and/or new interfaces, and then just start 
   replacing function calls to refer to the new functions. Comment 
   out and remove old ones only after all calls have been changed

   One possibile set of semantic units for vector operations:

       LHS (result):
       rV - real vector
       cV - complex vector

       Pointwise binary Operations:
       Sub   -> subtraction
       Add   -> addition
       Mul   -> pointwise multiplication
       Div   -> pointwise division

       Assignment:
       Eq     -> assignment
       Eq(Op) -> assignment to first vector operand

       RHS operands:
       V   -> vector on rhs (same as LHS by default)
       R   -> real vector with same value for all elements
       C   -> complex Vector with same value for all elements
       r   -> real prefactor multiplying all elements
       c   -> complex prefactor multiplying all elements
       Vr  -> Vector multiplied by real prefactor
       Vc  -> Vector multiplied by complex prefactor

       In what follows: A, B, C are vectors, while a, b are scalars 

       Simple Assignment:

       C = A        :  rV_EqV   (vector assignment)
       C = R        :  rV_EqR   (assign all elements same value)

       Pointwise Binary operations C = A Op B have form C_OpAB (two arguments)

       C = A + B    :   rV_AddVV
       C = A - B    :   rV_SubVV
       C = A + R    :   rV_AddVR
       C = A - R    :   rV_SubVR
       C = A * B    :   rV_MulVV   (element-wise multiplication)
       C = A / B    :   rV_DivVV   (element-wise division)
       C = Aa + Bb  :   rV_AddVrVr
       C = A + Bb   :   rV_AddVVr

       Increment operations A = A Op B have form A_EqOpB 
       (First operand must be a vector, same address as the LHS)

       A = A + B    :   rV_EqAddV
       A = A - B    :   rV_EqSubV
       A = A + R    :   rV_EqAddR   (pointwise add same value to all elements)
       A = A - R    :   rV_EqSubR   (pointwise sub same value from all)
       A = A*r      :   rV_EqMulr
       A = A + aB   :   rV_EqAddVr

       Corresponding functions that return a complex-valued vector
       will start with cV. Arguments on the RHS side will use V for
       a complex vector, c for a complex scalar that multiplies a
       vector, r for a real scalar that multiplies a vector, C for 
       a complex vector with the same value for all elements, R for 
       a real vector with the same value for all elements. If we 
       need a symbol for a real valued vector (which we may not)
       use U. 

       Possibility: We could consider creating a sub namespace of Pscf::Gpu 
       such as Pscf::Gpu::LinAlg if we thought that the extra name qualifier
       would improve clarity. CPU and GPU implementations of analogous 
       functions would already be segregated into Pscf::Gpu and Pscf::Cpu,
       so we wouldn't need it for that purpose. 

5) Kernels vs. C++ Wrapper functions

       For many required operations, we will probably want three types of 
       closely related function:

       1. A global cuda kernel like the existing kernels, in which the Block 
         and Thread counts have to be passed explicitly. This could be defined
         in pscf/gpu/LinearAlgebra

       2. A C++ function in which a ThreadGrid is passed as an argument, along
         with bare C pointers to memory on the GPU, and an array dimension.
         This would call a kernel internally. The presence of a ThreadGrid
         in the argument would distinguish the interface from that of an
         analogous kernel, so the name could be the same. This could also be
         defined in pscf/gpu/LinearAlgebra

       3. A C++ function that takes RField or RFieldDft containers.
         This would calls the C++ pointer version internally. This could take 
         a ThreadGrid as an argument or create one internally from knowledge
         of field array dimensions. The interface would be distinguished from
         that of the other two function types by the appearance of container
         types rather than pointers. This would have to be defined in a file
         in prdc/gpu, since that is where the containers are defined.

       - Proposal: Order of the first few parameters would be the same as in 
         order of equation, with the LHS vector listed first.  Array size 
         (if any) would be after arguments, and the ThreadGrid (if any) after 
         that.

       - Even the existing pspg code might be able to use some functions that 
         act on complex-valued data in order to operator on RFieldDft 
         containers.  We'd have to think about something that operates on 
         RFieldDft containers could use the same underlying kernels as 
         something that operates on a CField container (not yet created). 
         It depends in part on what data types cudaFFT is using for these 
         two types of data.

       - Field containers CField and (possibly) CFieldDft would be created
         in prdc/gpu and prdc/cpu

       - We would later add functions that act on complex data to 
         pscf/gpu/linearAlgebra, and analogous functions that act on CField
         containers to prdc/gpu

       - We need thorough unit tests to be written for all functions during
         development of these functions. These are simple, but humans still
         make mistakes, and its a lot of minor changes at once. 

6) Find locally defined kernels and replace them one-by-one with ones defined 
   in pscf/gpu or prdc/gpu:

     - Replace scaleRealData in fieldFFT.tpp 

     - Consider replacing some pointwise multiplication functions defined 
       in Block.

     - Consider replacing FFTBatched.tpp/scaleComplexData 

--------------------------------------------------------------------------
Parallel Reductions:

   After cleaning up operations that create or modify vectors, we could
   try to clean up parallel reduction kernels and wrappers.

1) Move parallel reduction kernels to private namespace in implementation
   of kernel wrappers, so not publically visible. 

    Example wrapper function for reductions:

       reduceSum
       reduceAbsMax

       Overloaded versions of wrappers for pointers and containers,
       as for vector operations. Pointer versions should take a 
       ThreadGrid as an argument.

       Some convention will be need to distinguish names of kernels
       from analogous C++ wrapper. The use of a ThreadGrid argument
       to the C++ wrapper may be enough, if done consistently. 

2) Rename some files:

       KernelWrappers -> Reductions (both kernels and C++ wrappers)

       Provide overloaded operations for field containers in 
       directories or files that define containers

       Move Helpers to pscf/gpu
      
