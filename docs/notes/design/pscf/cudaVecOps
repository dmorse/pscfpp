TODO (rpg GPU code):

Clean up of simple vector linear algebra kernel functions
----------------------------------------------------------

1) Create a new public branch vector in which to do clean up.
   Commit and push partial but functional changes to that.

2) Comment out (first) then erase (second) unused kernels.
   Some are found in solvers/Block.tpp and (possibly?) math/Helpers.cu
   (From Ryan: definitely some in math/Helpers.cu!)

3) Analyze what operations in the current rpg code are or should be 
   implemented by calling a standard linear algebra operation like
   one of those described below. That will give a list of operations
   that are needed immediately, and may identify some possible 
   operations that we actually don't need immediately. 

4) Most of the existing linear algebra operations use a consistent
   order in which the first argument is the LHS and the last is
   the array size, but at least one doesn't. Before changing function 
   names, clean up the syntax of any that don't to correspond to this 
   standard convention. This will make it simpler to change the names 
   later. We may be able to do this in stages, by first just changing 
   the names of Cuda kernels, testing that, and then changing from 
   cuda kernels with <<< ... >>> syntax to corresponding wrapper C++ 
   functions that use the ThreadGrid namespace internally. 

5) Establish more consistent function name conventions for a new
   set of functions in pscf/cuda/LinearAlgebra files.

   Proposal: One way to do this would be to write and test copies 
   with new names and/or new interfaces, and then just start 
   replacing function calls to refer to the new functions. Comment 
   out and remove old ones only after all calls have been changed

   Proposal for name conventions (current preference):

       Define all these functions in a namespace Pscf::Cuda::Vec.
       Use qualified names in which "Vec::" is explicit to make
       it clear that these are vector operations.

       Declare all of these functions in a new file pscf/cuda/Vec.h.
       Add include statements for this header and eventually remove 
       include statements for the LinearAlgebra.h header.

       Use overloading of arguments to distinguish input data types
       (real vs. complex) thus limiting the number of required function 
       names.

       Use V for vector, S for scalar for input argument(s). 
       Agument types V and S follow the operation name. 

       Use eq for unary assignment. The function eqV(A,B) thus 
       assigns vector B to a vector A (A=B) while, eqS(A,S)
       assigns scalar S to every element of vector A. 

       Use add, sub, mul div for binary operations. Start each
       function name with the binary operation in lower case. 
       Multiplication and division are interpreted as elementwise
       operations, like addition and subtraction.  The function 
       addVV(A,B,C) thus implements vector-vector addition 
       A[i] = B[i] + C[i], while addVS(A,B,c) implements vector 
       scalar addition A[i] = B[i] + c in which c is a scalar 
       that is added to every element of B.

       Use Eq after a binary operation name to denote in-place 
       operations (compound assignments), such as addEq, analogous 
       to C/C++ notation +=, -=, *=. The function addEqV(A,B) thus
       implements A[i] = A[i] + B[i] or A[i] += B[i].

       Use a lower case c (for "coefficient") after a V to indicate
       a coefficient (or scaling factor) that multiplies a vector.
       Thus addEqVc(A,B,c) implements A[i] += c*B[i].  Coefficients
       follow the vector that the multiply in both the name and
       the argument list.

       Unary operations such as exponentiation can appear to the
       right of assignment eq, a binary operation such as add or 
       a compound assignment. Thus addEqExpVc(A,B,c) represents
       A[i] += exp(c*B[i]).

       In examples below (but not in names) use upper case for 
       vectors, lower case for scalars:

       Unary assignment:

         eqV(A,B,n)  :  A[i] = B[i]  vector assignment
         eqS(A,s,n)  :  A[i] = s     assigment of scalar to every element

       Binary operations (distinct LHS memory location)

         addVV(A,B,C,n) :  A[i] = B[i] + C[i] vector-vector addition
         addVS(A,B,c,n) :  A[i] = B[i] + c    vector-scalar addition

       Compound assignment ("in place" operations)

         addEqV(A,B,n) :  A[i] += B[i]  (addition of vector V)
         addEqS(A,B,c) :  A[i] += c     (addition of scalar c)

       C interface: Order of the first few parameters would be the 
       same as in order of equation, with the LHS vector listed first.  
       Int vector / array size is list last, after all other arguments. 
       In Cuda kernels, vectors are passed as pointers (cudaReal*
       or cudaComplex*), scalars are passed as by value as cudaReal
       or cudaComplex. Vectors that are not modified (any after the 
       first argument) are passed as pointers to const (i.e.,
       cudaReal const * or cudaComplex const *).  Return value is 
       always void.

       Result data types (real or complex) are known from argument 
       types.  Binary operations involving inputs of the same type 
       (both cudaReal or both cudaComplex) yield a result with
       elements of that type. Operations involving complex and 
       real RHS arguments yield a complex result vector.
 
       Define kernel function in Pscf::Cuda::Vec::

       Use an underscore in names of kernel functions to distinguish
       them from corresponding C++ functions.

       Examples of interfaces (return type is void in all):

         _eqV(real* result, real const * a, int n);

         _addVV(real* result, real const * a, real const * b, int n);
         _addVS(real* result, real const * a, real b, int n);
         _addEqV(real* a, real const * b, int n)
         _addEqS(real* a, real b, int n)

         _addVV(complex* result, complex* a, real const * b, in n);
         _addVV(complex* result, complex const * a, complex const * b, 
              int n);
         _addVS(complex* result, complex const * a, complex b, int n);
         _addVS(complex* result, complex const * a, real b, int n);
         _addVS(complex* result, real const * a, complex b, int n);
         _addEqV(complex* a, complex const * b, int n)
         _addEqV(complex* a, real const * b, int n)
  
         _addEqS(complex* a, complex b, int n)
         _addEqS(complex* a, real b, int n)
  
       Here "real" and  "complex" denote cudaReal and cudaComplex.

       The number of possible functions involving only real numbers
       is not that huge, but expands a lot when we include possible
       binary operations that generate complex vectors with both real 
       and complex RHS arguments.

       Start by defining and renaming the ones that are already used
       in the code, and add others as we need them. The library 
       doesn't need to be exhaustive - just needs an unambigous set 
       of conventions that allows orderly growth.

5) Kernels vs. C++ Wrapper functions

       For many required operations with vector results, we will probably 
       want up to three types of closely related function:

       1. A __global__ cuda kernel like the existing kernels, for which 
          the Block and Thread counts have to be passed explicitly in 
          a <<< .... >> block. Names of these functions begin with an
          underbar (_), and all vector operations are defined in
          Pscf::Cuda::Vec.  Arrays are passed as pointers. 

          Example declaration (within Pscf::Cuda::Vec) :

          __global__ 
          void _addEqV(cudaReal * A, cudaReal const * B, int n)

          Example usage (in context with "using namespace Pscf::Cuda"):

             Vec::_addEqV<<nBlocks, nThreads>>(a,b,,n)

          Comment: The underscore prefix name convention would initially 
          be used only for names of Cuda kernels for which there are 
          corresponding C++ functions with the same name and interface.

          We might then consider establishing a convention in which 
          CUDA kernels are always distinguished by an underscore prefix, 
          since this is a compact syntax that we aren't using elsewhere
          to mean something else (class members have an _ suffix).
          If we decide to make the rule general, we'd document it in 
          the PSCF programmers style guide section of the manual in a 
          separate section on Cuda kernels.

          Recommendation: Make changes as need to make sure the order 
          of arguments of all existing linear algebra functions obey 
          a standard order (LHS first and vector dimension last) that is
          the same as the one we want to use in the new library BEFORE 
          changing names or header includes, to make the name change 
          as trivial as possible. 

          Recommendation: Create unit tests for existing functions
          before creating new ones, to add confidence during later
          transformations.

       2. A C++ function with the same interface and analogous name as
          the corresponding cuda kernel, without the underbar. Arrays 
          are pointers to global Gpu memory. A static ThreadGrid 
          functions is used internally to choose values for the block 
          and thread counts that are passed to the kernel that is called 
          internally.

          Example declaration (within Pscf::Cuda::Vec namespace):

             void addEqV(cudaReal* A, cudaReal const * B, int n) {
                int nb, nt;
                ThreadGrid::setThreadsLogical(n, nb, nt);
                _addEqV<<<nt, nt>>>(A, B, n);
             }

          Example usage (calling location):

             In context with "using namespace Pscf::Cuda" :

                  Vec::addEqV(a,b,n)

             In context with "using namespace Pscf" :

                  Cuda::Vec::addEqV(a,b,n)

          Note: Syntax might allow analogous functions to be defined
          and used in Cpu code, by using Pscf::Cpu instead

          Comment: The internal call to ThreadGrid::setThreadsLogical
          is a zero cost operation if the logical number of threads is
          the same as the used in the most recently called thread,
          since it the implementation of that function is designed to 
          use the existing values of nBlocks and nThreads if the 
          logical number of threads (i.e., the array dimension) is
          unchanged.

       3. Possibly a C++ function that takes Field<T> containers.
          This would calls the C++ pointer version internally. 
          This could take a ThreadGrid as an argument or create one 
          internally from knowledge of field array dimensions. 
          The interface would be distinguished from that of the other two 
          function types by the appearance of container types rather 
          than pointers. This would have to be defined in namespace
          Prdc::Cuda, since that is where the container templates
          are defined. 
   
       -  Using Field<cudaReal> and Field<cudaComplex> rather than
          RField<D>, RFieldDft<D> and CField<D> would avoid the need
          to treat D as a template parameter, and allow the same 
          functions to be used for RFieldDft<D> and CField<D> 
          containers.

       -  We need thorough unit tests to be written for all functions 
          during development of these functions. These are simple, but 
          humans still make mistakes, and its a lot of minor changes at 
          once. 

6) Find locally defined kernels and replace them one-by-one with ones 
defined in pscf/gpu or prdc/gpu when possible:

     - Replace scaleRealData in fieldFFT.tpp 

     - Consider replacing some pointwise multiplication functions defined 
       in Block, and perhaps assignment to an exponential. 

     - Consider replacing FFTBatched.tpp/scaleComplexData 

--------------------------------------------------------------------------
Parallel Reductions:

   After cleaning up operations that create or modify vectors, we could
   try to clean up parallel reduction kernels and wrappers.

1) Move parallel reduction kernels to private namespace in implementation
   of kernel wrappers, so not publically visible. 

    Example wrapper function for reductions:

       reduceSum
       reduceAbsMax

       Overloaded versions of wrappers for pointers and containers,
       as for vector operations. Pointer versions should take a 
       ThreadGrid as an argument.

       Some convention will be need to distinguish names of kernels
       from analogous C++ wrapper. The use of a ThreadGrid argument
       to the C++ wrapper may be enough, if done consistently. 

2) Rename some files:

       KernelWrappers -> Reductions (both kernels and C++ wrappers)

       Provide overloaded operations for field containers in 
       directories or files that define containers

       Move Helpers to pscf/gpu
      
